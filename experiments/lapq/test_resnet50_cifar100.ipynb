{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda:2'\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torchvision.datasets as Datasets\n",
    "from torchvision import transforms as tfms\n",
    "from torch.utils.data import DataLoader\n",
    "sys.path.append(\"../../\")\n",
    "torch.cuda.set_device(int(DEVICE[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = ((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
    "train_tfms = tfms.Compose([\n",
    "    tfms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
    "    tfms.RandomHorizontalFlip(),\n",
    "    tfms.ToTensor(),\n",
    "    tfms.Normalize(*stats, inplace=True)\n",
    "])\n",
    "test_tfms = tfms.Compose([\n",
    "    tfms.ToTensor(),\n",
    "    tfms.Normalize(*stats)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar100_train = Datasets.CIFAR100(root='./data', train=True, download=True, transform=test_tfms)\n",
    "cifar100_test = Datasets.CIFAR100(root='./data', train=False, download=True, transform=test_tfms)\n",
    "\n",
    "train_loader = DataLoader(cifar100_train, shuffle=True, num_workers=1, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(cifar100_test, shuffle=False, num_workers=1, batch_size=2*BATCH_SIZE)\n",
    "\n",
    "dataloaders = {\"train\" : train_loader , \"val\" : test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from trailmet.models import resnet\n",
    "from trailmet.algorithms.quantize.lapq import LAPQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "cnn=resnet.make_resnet50(100,32)\n",
    "checkpoint = torch.load(\"./resnet50_cifar100-pretrained.pth\", map_location=DEVICE)\n",
    "cnn.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:05<00:00,  3.95it/s, acc1=72.5, acc5=91.5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(72.53963699340821, 91.5182674407959)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test model\n",
    "from trailmet.algorithms.algorithms import BaseAlgorithm\n",
    "BaseAlgorithm().test(model=cnn, dataloader=test_loader, device=torch.device(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:05<00:00,  3.83it/s, acc1=12.6, acc5=31.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization (W4A8) accuracy before LAPQ: (12.637867641448974, 31.852021980285645)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:33<00:00,  3.31s/it, loss=0.583, p_val=4]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:06<00:00,  3.31it/s, acc1=66.7, acc5=87.3, loss=1.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> p intr : 3.16\n",
      "==> loss : 1.4545\n",
      "==> acc@1 | acc@5 : 66.6843 | 87.2691\n",
      "==> iteration: 0, minimum loss so far: 0.2761\n",
      "==> iteration: 50, minimum loss so far: 0.2543\n",
      "==> iteration: 100, minimum loss so far: 0.2207\n",
      "==> iteration: 150, minimum loss so far: 0.2196\n",
      "==> iteration: 200, minimum loss so far: 0.2193\n",
      "==> iteration: 250, minimum loss so far: 0.2178\n",
      "==> iteration: 300, minimum loss so far: 0.2154\n",
      "==> iteration: 350, minimum loss so far: 0.2117\n",
      "==> iteration: 400, minimum loss so far: 0.2111\n",
      "==> iteration: 450, minimum loss so far: 0.2045\n",
      "==> iteration: 500, minimum loss so far: 0.2045\n",
      "==> iteration: 550, minimum loss so far: 0.2044\n",
      "==> iteration: 600, minimum loss so far: 0.2042\n",
      "==> iteration: 650, minimum loss so far: 0.2030\n",
      "==> iteration: 700, minimum loss so far: 0.2004\n",
      "==> iteration: 750, minimum loss so far: 0.1984\n",
      "==> iteration: 800, minimum loss so far: 0.1943\n",
      "==> iteration: 850, minimum loss so far: 0.1941\n",
      "==> iteration: 900, minimum loss so far: 0.1941\n",
      "==> iteration: 950, minimum loss so far: 0.1940\n",
      "==> iteration: 1000, minimum loss so far: 0.1940\n",
      "==> iteration: 1050, minimum loss so far: 0.1940\n",
      "==> iteration: 1100, minimum loss so far: 0.1914\n",
      "==> iteration: 1150, minimum loss so far: 0.1910\n",
      "==> iteration: 1200, minimum loss so far: 0.1905\n",
      "==> iteration: 1250, minimum loss so far: 0.1897\n",
      "==> iteration: 1300, minimum loss so far: 0.1895\n",
      "==> iteration: 1350, minimum loss so far: 0.1872\n",
      "==> iteration: 1400, minimum loss so far: 0.1805\n",
      "==> iteration: 1450, minimum loss so far: 0.1758\n"
     ]
    }
   ],
   "source": [
    "# quantize model\n",
    "kwargs = {\n",
    "    'W_BITS':4, \n",
    "    'A_BITS':8, \n",
    "    'ACT_QUANT':True,\n",
    "    'CALIB_BATCHES':1024//BATCH_SIZE, \n",
    "    'MAX_ITER':1,\n",
    "    'MAX_FEV':1,\n",
    "    'VERBOSE':True,\n",
    "    'PRINT_FREQ':50,\n",
    "    'GPU_ID':int(DEVICE[-1]),\n",
    "    'SEED':42\n",
    "    }\n",
    "qnn = LAPQ(cnn, dataloaders, **kwargs)\n",
    "qnn.compress_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "96762580dc771c728ac9a1b8aa29a3a420bc09545a8c1a32553175fbb1f6eb2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
